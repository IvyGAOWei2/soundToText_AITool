# ğŸ§ Speech-to-Text Transcriber (Whisper + Faster-Whisper)

Generate clean transcripts or SRT subtitles from any audio file using Whisper (via Faster-Whisper).

---

## ğŸŒŸ Features

- âœ” Supports **Whisper Medium model** (with GPU acceleration if available)
- âœ” **Two output modes**:

  - **SRT subtitles** (with timestamps)
  - **Plain text transcript**

- âœ” Automatically detects language
- âœ” Uses **Faster-Whisper** for high-speed inference
- âœ” Runs on **CPU or GPU** automatically (depending on your system)

---

# ğŸš€ 1. Environment Setup (Conda)

Create and activate a new Conda environment:

```bash
conda create -n whisper python=3.10 -y
conda activate whisper
```

---

# âš¡ 2. Install PyTorch (with optional GPU support)

### If your computer has an NVIDIA GPU

Install CUDA-enabled PyTorch, eg:

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### If your computer does NOT have a GPU

Install CPU-only PyTorch:

```bash
pip install torch torchvision torchaudio
```

You can still run the project â€” it simply uses CPU fallback.

---

# ğŸ¤ 3. Install Faster-Whisper

```bash
pip install faster-whisper
```

Faster-Whisper will automatically download the model you specify (e.g., `small`, `medium`, `medium.en`, `large-v2`, etc.) from HuggingFace on first run.

---

# ğŸ¯ 4. Choosing a Model

This project currently defaults to:

```python
model_size = "medium"
```

Because:

- Whisper **medium** provides a good balance of accuracy and speed
- It fits well into 6GB GPUs (e.g., RTX 4050)
- Users without GPUs can still run it on CPU

You may change:

```python
model_size = "small"
model_size = "medium"
model_size = "medium.en"
model_size = "large-v2"
model_size = "large-v3"
```

All official models are hosted at:
[https://huggingface.co/Systran](https://huggingface.co/Systran)

---

# ğŸ“ 5. Project Structure

---

# ğŸ“ 6. How to Run

## â¤ **Run SRT Subtitle Generator**

Script: `run-srt.py`

```bash
python run-srt.py
```

Output example:

```
SRT saved toï¼šoutput-srt/yourfile - transcript.srt
Detected language 'en' with probability 0.98
```

---

## â¤ **Run Plain Text Transcript Generator**

Script: `run-txt.py`

```bash
python run-txt.py
```

Output example:

```
Transcription saved to: output-text/yourfile - transcript.txt
```

---

# ğŸ§  7. How It Works (Simplified Pipeline)

```
Audio (.mp3 / .wav / etc.)
      â†“
Faster-Whisper model (medium)
      â†“
Segment detection (start/end)
      â†“
Language detection
      â†“
Output:
    â†’ SRT with timestamps
    â†’ Plain text transcript
```

---

# ğŸ’¬ 8. License

Whisper & Faster-Whisper follow MIT License.
Model weights follow the HuggingFace license terms.
